nohup: ignoring input
Namespace(adv_loss='wgan-gp', attn_path='./attn', batch_size=16, beta1=0.0, beta2=0.9, d_conv_dim=64, d_iters=5, d_lr=0.0004, dataset='cifar', g_conv_dim=64, g_lr=0.0001, g_num=5, image_path='./data', imsize=32, lambda_gp=10, log_path='./logs', log_step=10, lr_decay=0.95, model='sagan', model_save_path='./models', model_save_step=1.0, num_workers=2, parallel=False, pretrained_model=None, sample_path='./samples', sample_step=100, total_step=1000000, train=True, use_tensorboard=False, version='sagan_1', z_dim=128)
[[[[1.16654001e-02 6.65879459e-04 7.52911554e-04 ... 4.70575131e-03
    6.17570069e-04 3.69739230e-03]
   [1.16411624e-02 6.71329850e-04 7.52669410e-04 ... 4.71026637e-03
    6.17689628e-04 3.69906961e-03]
   [1.16469152e-02 6.69777626e-04 7.52434426e-04 ... 4.71187430e-03
    6.17869257e-04 3.69910151e-03]
   ...
   [9.81565937e-03 2.18812362e-04 7.64337252e-04 ... 4.69113933e-03
    6.05562527e-04 3.60879162e-03]
   [9.79032367e-03 2.05391450e-04 7.64546741e-04 ... 4.69840597e-03
    6.05335226e-04 3.60921607e-03]
   [8.14932026e-03 7.49601750e-04 7.12499663e-04 ... 5.75178862e-03
    6.72358205e-04 3.95538192e-03]]

  [[1.16654001e-02 6.65879459e-04 7.52911554e-04 ... 4.70575131e-03
    6.17570069e-04 3.69739230e-03]
   [1.16411624e-02 6.71329850e-04 7.52669410e-04 ... 4.71026637e-03
    6.17689628e-04 3.69906961e-03]
   [1.16469152e-02 6.69777626e-04 7.52434426e-04 ... 4.71187430e-03
    6.17869257e-04 3.69910151e-03]
   ...
   [9.81565937e-03 2.18812362e-04 7.64337252e-04 ... 4.69113933e-03
    6.05562527e-04 3.60879162e-03]
   [9.79032367e-03 2.05391450e-04 7.64546741e-04 ... 4.69840597e-03
    6.05335226e-04 3.60921607e-03]
   [8.14932026e-03 7.49601750e-04 7.12499663e-04 ... 5.75178862e-03
    6.72358205e-04 3.95538192e-03]]

  [[1.16654001e-02 6.65879459e-04 7.52911554e-04 ... 4.70575131e-03
    6.17570069e-04 3.69739230e-03]
   [1.16411624e-02 6.71329850e-04 7.52669410e-04 ... 4.71026637e-03
    6.17689628e-04 3.69906961e-03]
   [1.16469152e-02 6.69777626e-04 7.52434426e-04 ... 4.71187430e-03
    6.17869257e-04 3.69910151e-03]
   ...
   [9.81565937e-03 2.18812362e-04 7.64337252e-04 ... 4.69113933e-03
    6.05562527e-04 3.60879162e-03]
   [9.79032367e-03 2.05391450e-04 7.64546741e-04 ... 4.69840597e-03
    6.05335226e-04 3.60921607e-03]
   [8.14932026e-03 7.49601750e-04 7.12499663e-04 ... 5.75178862e-03
    6.72358205e-04 3.95538192e-03]]]


 [[[1.16333477e-02 6.65057509e-04 7.51289772e-04 ... 4.71435860e-03
    6.18387188e-04 3.69757786e-03]
   [1.16190175e-02 6.68859226e-04 7.52195658e-04 ... 4.71107615e-03
    6.17955520e-04 3.69945774e-03]
   [1.16216345e-02 6.66313223e-04 7.51837273e-04 ... 4.71211178e-03
    6.17709826e-04 3.69966426e-03]
   ...
   [9.78832878e-03 1.16771800e-04 7.64002674e-04 ... 4.82614757e-03
    6.07349968e-04 3.61408736e-03]
   [9.74182412e-03 9.59467361e-05 7.64005294e-04 ... 4.83366335e-03
    6.07579132e-04 3.61509062e-03]
   [1.11782132e-02 7.12842273e-04 7.21959048e-04 ... 4.82674548e-03
    6.13673707e-04 3.73919308e-03]]

  [[1.16333477e-02 6.65057509e-04 7.51289772e-04 ... 4.71435860e-03
    6.18387188e-04 3.69757786e-03]
   [1.16190175e-02 6.68859226e-04 7.52195658e-04 ... 4.71107615e-03
    6.17955520e-04 3.69945774e-03]
   [1.16216345e-02 6.66313223e-04 7.51837273e-04 ... 4.71211178e-03
    6.17709826e-04 3.69966426e-03]
   ...
   [9.78832878e-03 1.16771800e-04 7.64002674e-04 ... 4.82614757e-03
    6.07349968e-04 3.61408736e-03]
   [9.74182412e-03 9.59467361e-05 7.64005294e-04 ... 4.83366335e-03
    6.07579132e-04 3.61509062e-03]
   [1.11782132e-02 7.12842273e-04 7.21959048e-04 ... 4.82674548e-03
    6.13673707e-04 3.73919308e-03]]

  [[1.16333477e-02 6.65057509e-04 7.51289772e-04 ... 4.71435860e-03
    6.18387188e-04 3.69757786e-03]
   [1.16190175e-02 6.68859226e-04 7.52195658e-04 ... 4.71107615e-03
    6.17955520e-04 3.69945774e-03]
   [1.16216345e-02 6.66313223e-04 7.51837273e-04 ... 4.71211178e-03
    6.17709826e-04 3.69966426e-03]
   ...
   [9.78832878e-03 1.16771800e-04 7.64002674e-04 ... 4.82614757e-03
    6.07349968e-04 3.61408736e-03]
   [9.74182412e-03 9.59467361e-05 7.64005294e-04 ... 4.83366335e-03
    6.07579132e-04 3.61509062e-03]
   [1.11782132e-02 7.12842273e-04 7.21959048e-04 ... 4.82674548e-03
    6.13673707e-04 3.73919308e-03]]]


 [[[1.15467682e-02 6.71463495e-04 7.52522261e-04 ... 4.71229386e-03
    6.17925252e-04 3.70478816e-03]
   [1.15949875e-02 6.56601565e-04 7.52810738e-04 ... 4.68259864e-03
    6.16159872e-04 3.69239133e-03]
   [1.15671195e-02 6.73484232e-04 7.52457650e-04 ... 4.69908956e-03
    6.17156969e-04 3.70073342e-03]
   ...
   [9.05347615e-03 1.86168123e-04 7.63929100e-04 ... 4.59886761e-03
    6.01502310e-04 3.57479323e-03]
   [9.06033348e-03 1.84791803e-04 7.63620483e-04 ... 4.60395077e-03
    6.01715059e-04 3.57476017e-03]
   [9.33417678e-03 3.41067353e-04 7.84302480e-04 ... 4.46390733e-03
    5.96841972e-04 3.53985489e-03]]

  [[1.15467682e-02 6.71463495e-04 7.52522261e-04 ... 4.71229386e-03
    6.17925252e-04 3.70478816e-03]
   [1.15949875e-02 6.56601565e-04 7.52810738e-04 ... 4.68259864e-03
    6.16159872e-04 3.69239133e-03]
   [1.15671195e-02 6.73484232e-04 7.52457650e-04 ... 4.69908956e-03
    6.17156969e-04 3.70073342e-03]
   ...
   [9.05347615e-03 1.86168123e-04 7.63929100e-04 ... 4.59886761e-03
    6.01502310e-04 3.57479323e-03]
   [9.06033348e-03 1.84791803e-04 7.63620483e-04 ... 4.60395077e-03
    6.01715059e-04 3.57476017e-03]
   [9.33417678e-03 3.41067353e-04 7.84302480e-04 ... 4.46390733e-03
    5.96841972e-04 3.53985489e-03]]

  [[1.15467682e-02 6.71463495e-04 7.52522261e-04 ... 4.71229386e-03
    6.17925252e-04 3.70478816e-03]
   [1.15949875e-02 6.56601565e-04 7.52810738e-04 ... 4.68259864e-03
    6.16159872e-04 3.69239133e-03]
   [1.15671195e-02 6.73484232e-04 7.52457650e-04 ... 4.69908956e-03
    6.17156969e-04 3.70073342e-03]
   ...
   [9.05347615e-03 1.86168123e-04 7.63929100e-04 ... 4.59886761e-03
    6.01502310e-04 3.57479323e-03]
   [9.06033348e-03 1.84791803e-04 7.63620483e-04 ... 4.60395077e-03
    6.01715059e-04 3.57476017e-03]
   [9.33417678e-03 3.41067353e-04 7.84302480e-04 ... 4.46390733e-03
    5.96841972e-04 3.53985489e-03]]]


 ...


 [[[1.16502093e-02 6.59948448e-04 7.50656240e-04 ... 4.71842103e-03
    6.18949009e-04 3.69812152e-03]
   [1.16795348e-02 6.51952752e-04 7.50833307e-04 ... 4.71128756e-03
    6.18322811e-04 3.69385350e-03]
   [1.16794864e-02 6.49948721e-04 7.51309446e-04 ... 4.71220491e-03
    6.18654536e-04 3.69361788e-03]
   ...
   [8.92496109e-03 7.11762550e-05 7.66259851e-04 ... 4.67352336e-03
    6.03063905e-04 3.58391111e-03]
   [8.91986117e-03 6.90549932e-05 7.66116253e-04 ... 4.67309263e-03
    6.03175082e-04 3.58372671e-03]
   [6.97567733e-03 6.35516946e-04 6.87048188e-04 ... 5.46420040e-03
    6.90526387e-04 3.95243289e-03]]

  [[1.16502093e-02 6.59948448e-04 7.50656240e-04 ... 4.71842103e-03
    6.18949009e-04 3.69812152e-03]
   [1.16795348e-02 6.51952752e-04 7.50833307e-04 ... 4.71128756e-03
    6.18322811e-04 3.69385350e-03]
   [1.16794864e-02 6.49948721e-04 7.51309446e-04 ... 4.71220491e-03
    6.18654536e-04 3.69361788e-03]
   ...
   [8.92496109e-03 7.11762550e-05 7.66259851e-04 ... 4.67352336e-03
    6.03063905e-04 3.58391111e-03]
   [8.91986117e-03 6.90549932e-05 7.66116253e-04 ... 4.67309263e-03
    6.03175082e-04 3.58372671e-03]
   [6.97567733e-03 6.35516946e-04 6.87048188e-04 ... 5.46420040e-03
    6.90526387e-04 3.95243289e-03]]

  [[1.16502093e-02 6.59948448e-04 7.50656240e-04 ... 4.71842103e-03
    6.18949009e-04 3.69812152e-03]
   [1.16795348e-02 6.51952752e-04 7.50833307e-04 ... 4.71128756e-03
    6.18322811e-04 3.69385350e-03]
   [1.16794864e-02 6.49948721e-04 7.51309446e-04 ... 4.71220491e-03
    6.18654536e-04 3.69361788e-03]
   ...
   [8.92496109e-03 7.11762550e-05 7.66259851e-04 ... 4.67352336e-03
    6.03063905e-04 3.58391111e-03]
   [8.91986117e-03 6.90549932e-05 7.66116253e-04 ... 4.67309263e-03
    6.03175082e-04 3.58372671e-03]
   [6.97567733e-03 6.35516946e-04 6.87048188e-04 ... 5.46420040e-03
    6.90526387e-04 3.95243289e-03]]]


 [[[1.14434361e-02 6.85239444e-04 7.53109867e-04 ... 4.71987296e-03
    6.17254293e-04 3.70995235e-03]
   [1.15132025e-02 6.68275403e-04 7.53245607e-04 ... 4.70798276e-03
    6.15732744e-04 3.70165403e-03]
   [1.15069924e-02 6.67502289e-04 7.53357657e-04 ... 4.70637484e-03
    6.15851197e-04 3.70154809e-03]
   ...
   [9.39040538e-03 3.24571563e-04 7.75900320e-04 ... 4.50361008e-03
    5.99960913e-04 3.54705751e-03]
   [9.39503033e-03 3.22538079e-04 7.76202942e-04 ... 4.50312719e-03
    5.99901483e-04 3.54718626e-03]
   [6.81871502e-03 6.96339819e-04 6.85175008e-04 ... 5.50381793e-03
    6.92962669e-04 3.99205601e-03]]

  [[1.14434361e-02 6.85239444e-04 7.53109867e-04 ... 4.71987296e-03
    6.17254293e-04 3.70995235e-03]
   [1.15132025e-02 6.68275403e-04 7.53245607e-04 ... 4.70798276e-03
    6.15732744e-04 3.70165403e-03]
   [1.15069924e-02 6.67502289e-04 7.53357657e-04 ... 4.70637484e-03
    6.15851197e-04 3.70154809e-03]
   ...
   [9.39040538e-03 3.24571563e-04 7.75900320e-04 ... 4.50361008e-03
    5.99960913e-04 3.54705751e-03]
   [9.39503033e-03 3.22538079e-04 7.76202942e-04 ... 4.50312719e-03
    5.99901483e-04 3.54718626e-03]
   [6.81871502e-03 6.96339819e-04 6.85175008e-04 ... 5.50381793e-03
    6.92962669e-04 3.99205601e-03]]

  [[1.14434361e-02 6.85239444e-04 7.53109867e-04 ... 4.71987296e-03
    6.17254293e-04 3.70995235e-03]
   [1.15132025e-02 6.68275403e-04 7.53245607e-04 ... 4.70798276e-03
    6.15732744e-04 3.70165403e-03]
   [1.15069924e-02 6.67502289e-04 7.53357657e-04 ... 4.70637484e-03
    6.15851197e-04 3.70154809e-03]
   ...
   [9.39040538e-03 3.24571563e-04 7.75900320e-04 ... 4.50361008e-03
    5.99960913e-04 3.54705751e-03]
   [9.39503033e-03 3.22538079e-04 7.76202942e-04 ... 4.50312719e-03
    5.99901483e-04 3.54718626e-03]
   [6.81871502e-03 6.96339819e-04 6.85175008e-04 ... 5.50381793e-03
    6.92962669e-04 3.99205601e-03]]]


 [[[1.16526131e-02 6.64726191e-04 7.52388150e-04 ... 4.70858812e-03
    6.17787766e-04 3.69751500e-03]
   [1.16019482e-02 6.56459248e-04 7.50958454e-04 ... 4.72026272e-03
    6.18905120e-04 3.69992852e-03]
   [1.15983123e-02 6.55188400e-04 7.50661769e-04 ... 4.72068973e-03
    6.18933584e-04 3.69949453e-03]
   ...
   [5.38975000e-03 6.65944128e-04 7.34516245e-04 ... 5.28513780e-03
    6.84102823e-04 3.95847019e-03]
   [5.39247086e-03 6.64434163e-04 7.34536210e-04 ... 5.28617762e-03
    6.84297062e-04 3.95867834e-03]
   [1.04371142e-02 5.48597833e-04 7.01013370e-04 ... 4.56569297e-03
    6.28095004e-04 3.67043726e-03]]

  [[1.16526131e-02 6.64726191e-04 7.52388150e-04 ... 4.70858812e-03
    6.17787766e-04 3.69751500e-03]
   [1.16019482e-02 6.56459248e-04 7.50958454e-04 ... 4.72026272e-03
    6.18905120e-04 3.69992852e-03]
   [1.15983123e-02 6.55188400e-04 7.50661769e-04 ... 4.72068973e-03
    6.18933584e-04 3.69949453e-03]
   ...
   [5.38975000e-03 6.65944128e-04 7.34516245e-04 ... 5.28513780e-03
    6.84102823e-04 3.95847019e-03]
   [5.39247086e-03 6.64434163e-04 7.34536210e-04 ... 5.28617762e-03
    6.84297062e-04 3.95867834e-03]
   [1.04371142e-02 5.48597833e-04 7.01013370e-04 ... 4.56569297e-03
    6.28095004e-04 3.67043726e-03]]

  [[1.16526131e-02 6.64726191e-04 7.52388150e-04 ... 4.70858812e-03
    6.17787766e-04 3.69751500e-03]
   [1.16019482e-02 6.56459248e-04 7.50958454e-04 ... 4.72026272e-03
    6.18905120e-04 3.69992852e-03]
   [1.15983123e-02 6.55188400e-04 7.50661769e-04 ... 4.72068973e-03
    6.18933584e-04 3.69949453e-03]
   ...
   [5.38975000e-03 6.65944128e-04 7.34516245e-04 ... 5.28513780e-03
    6.84102823e-04 3.95847019e-03]
   [5.39247086e-03 6.64434163e-04 7.34536210e-04 ... 5.28617762e-03
    6.84297062e-04 3.95867834e-03]
   [1.04371142e-02 5.48597833e-04 7.01013370e-04 ... 4.56569297e-03
    6.28095004e-04 3.67043726e-03]]]]
number of training examples = 72576
X_train shape: (72576, 3, 37, 30)
Y_train shape: (72576,)
Generator(
  (label_emb): Embedding(4, 4)
  (l4): Sequential(
    (0): SpectralNorm(
      (module): ConvTranspose2d(64, 32, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (l1): Sequential(
    (0): SpectralNorm(
      (module): ConvTranspose2d(512, 256, kernel_size=(4, 4), stride=(1, 1))
    )
    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (l2): Sequential(
    (0): SpectralNorm(
      (module): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (l3): Sequential(
    (0): SpectralNorm(
      (module): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): ReLU()
  )
  (last): Sequential(
    (0): ConvTranspose2d(32, 3, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    (1): Flatten(start_dim=1, end_dim=-1)
    (2): Linear(in_features=37632, out_features=3330, bias=True)
    (3): Unflatten(dim=1, unflattened_size=(3, 37, 30))
    (4): Tanh()
  )
  (attn1): Self_Attn(
    (query_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
    (key_conv): Conv2d(64, 8, kernel_size=(1, 1), stride=(1, 1))
    (value_conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))
    (softmax): Softmax(dim=-1)
  )
  (attn2): Self_Attn(
    (query_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
    (key_conv): Conv2d(32, 4, kernel_size=(1, 1), stride=(1, 1))
    (value_conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1))
    (softmax): Softmax(dim=-1)
  )
)
Discriminator(
  (label_emb): Embedding(4, 4)
  (l4): Sequential(
    (0): SpectralNorm(
      (module): Conv2d(256, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): LeakyReLU(negative_slope=0.1)
  )
  (l1): Sequential(
    (0): SpectralNorm(
      (module): Conv2d(12, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): LeakyReLU(negative_slope=0.1)
  )
  (l2): Sequential(
    (0): SpectralNorm(
      (module): Conv2d(64, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): LeakyReLU(negative_slope=0.1)
  )
  (l3): Sequential(
    (0): SpectralNorm(
      (module): Conv2d(128, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))
    )
    (1): LeakyReLU(negative_slope=0.1)
  )
  (last): Sequential(
    (0): Conv2d(512, 1, kernel_size=(1, 1), stride=(1, 1))
  )
  (attn1): Self_Attn(
    (query_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (key_conv): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))
    (value_conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (softmax): Softmax(dim=-1)
  )
  (attn2): Self_Attn(
    (query_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
    (key_conv): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))
    (value_conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1))
    (softmax): Softmax(dim=-1)
  )
)
Elapsed [0:00:01.590228], G_step [10/1000000], D_step[10/1000000], d_out_real: -0.0280,  ave_gamma_l3: 0.0002, ave_gamma_l4: 0.0001
Elapsed [0:00:02.522309], G_step [20/1000000], D_step[20/1000000], d_out_real: 0.0155,  ave_gamma_l3: -0.0003, ave_gamma_l4: -0.0005
